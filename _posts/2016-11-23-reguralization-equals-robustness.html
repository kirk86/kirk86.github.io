<div class="HTML">
<p>
&#x2014;
layout: post
title: "Reguralization equals Robustness"
date: 2016-11-23
comments: true
archive: false
tags: reguralization-equals-robustness
excerpt: Reguralization equals Robustness
&#x2014;
</p>

</div>

<p>
<b>Reguralization = Robustness</b>
</p>


<p>
I've recently come across a nice <a href="http://hunch.net/?p=197">article</a> which describes the
relationsihp between <code>reguralization</code> and <code>robustness</code> from the
machine learning perspective. Even though the article itself is and
old blog post I still find valuable from my own work, and especially
for someone who is new in the world of machine learning trying to
understand and getter a better grasp of the field. From that artcile I
kept out two things:
</p>


<ol class="org-ol">
<li>reguralization \(\rightarrow\) stable/stability \(\rightarrow\) robust</li>

<li>We cannot learn from noisy data without some form of
reguralization, because we end up fitting the noise. I.e. slack
variables in SVM, needed when data are not linearly separable. Not
entirely true since slack variables are still needed even when data
might be separable.</li>
</ol>
